{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COMS 4995_002 Deep Learning Assignment 1\n",
    "Due on Monday, Oct 9, 11:59pm\n",
    "\n",
    "This assignment can be done in groups of at most 3 students. Everyone must submit on Courseworks individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the UNIs of your group (if applicable)\n",
    "\n",
    "Member 1: Pulkit Jain, pj2313\n",
    "\n",
    "Member 2: Greg Kocher, gk2500\n",
    "\n",
    "Member 3: Ratheet Pandya, rp2707"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import glob\n",
    "import sys\n",
    "# you shouldn't need to make any more imports\n",
    "#import gc\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True#False#True\n",
    "class NeuralNetwork(object):\n",
    "    \"\"\"\n",
    "    Abstraction of neural network.\n",
    "    Stores parameters, activations, cached values. \n",
    "    Provides necessary functions for training and prediction. \n",
    "    \"\"\"\n",
    "    def __init__(self, layer_dimensions, drop_prob=0.0, reg_lambda=0.0, K_iters_alpha_drop=500, gamma=.90, do_reflection=True):\n",
    "        \"\"\"\n",
    "        Initializes the weights and biases for each layer\n",
    "        :param layer_dimensions: (list) number of nodes in each layer\n",
    "        :param drop_prob: drop probability for dropout layers. Only required in part 2 of the assignment\n",
    "        :param reg_lambda: regularization parameter. Only required in part 2 of the assignment\n",
    "        \"\"\"\n",
    "        #np.random.seed(1)\n",
    "        \n",
    "        self.parameters = {\n",
    "            'layerDimensions' : layer_dimensions\n",
    "        }\n",
    "        self.num_layers = len(layer_dimensions)\n",
    "        self.drop_prob = drop_prob\n",
    "        self.reg_lambda = reg_lambda\n",
    "        \n",
    "        #Stepwise exponentially decaying learning rate:\n",
    "        #every K iterations, learning rate alpha is multiplied\n",
    "        #by 0<gamma<=1\n",
    "        #To NOT do this and just use constant alpha,\n",
    "        #just set gamma = 1 [or K bigger than you would ever reach]\n",
    "        self.K_iters_alpha_drop = K_iters_alpha_drop#500\n",
    "        self.gamma = gamma#.90\n",
    "        \n",
    "        #Counter used for debugging and updating alpha\n",
    "        self.iterations_finished = 0\n",
    "        \n",
    "        #The weights and biaseswe are optimizing\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        #FOr debugging\n",
    "        self.training_accuracies = []\n",
    "        self.validation_accuracies = []\n",
    "        self.data_loss = []\n",
    "        self.regularization_loss = []\n",
    "        self.weights_means = []\n",
    "        self.dW_means = []\n",
    "        self.weights_sds = []\n",
    "        self.dW_sds = []        \n",
    "        \n",
    "        #Whether to do left/right reflection\n",
    "        self.do_reflection = do_reflection\n",
    "        \n",
    "                \n",
    "        \"\"\"\n",
    "        other ideas for increased performance:\n",
    "        - TA's suggested batchnorm layers\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def LeftRightReflection(self, X_batch, y_batch, prob_reflect=.5):\n",
    "        \"\"\"\n",
    "        As basic form of data augmentation,\n",
    "        reflect images left-right with some probability.\n",
    "        \n",
    "        Only left-right since in many of the cifar images,\n",
    "        there is a clear up-down direction because of real\n",
    "        world gravity. So also doing up-down reflection \n",
    "        would be artificial. SO only do left-right.\n",
    "        \n",
    "        Technically it would be better to only have\n",
    "        either image or image' in a given batch (to\n",
    "        not have both the image and its reflection, \n",
    "        because both in the same batch way introduce\n",
    "        bad symmetries). But just try this for now, and\n",
    "        use a probability so that not every image has\n",
    "        its reflection.\n",
    "        \n",
    "        --> Actually, at first, just relfect all images \n",
    "        and se what happens...\n",
    "        \"\"\"\n",
    "        \n",
    "        #t=X_train[:,:5]\n",
    "        #print(t.shape)\n",
    "        #g=[i.reshape(32,32,3) for i in t.T]\n",
    "        #plt.figure()\n",
    "        #plt.imshow(g[0])\n",
    "        #plt.show()\n",
    "        #h=[np.fliplr(i) for i in g]\n",
    "        #plt.figure()\n",
    "        #plt.imshow(h[0])\n",
    "        #plt.show()\n",
    "        #j=np.vstack(([i.flatten() for i in h])).T\n",
    "        #print(j.shape)\n",
    "        #print(t[:,0])\n",
    "        #print(j[:,0])\n",
    "        #_,u1 = np.unique(t[:,0],return_counts=True)\n",
    "        #_,u2 = np.unique(j[:,0],return_counts=True)\n",
    "        #print(u1==u2)\n",
    "        \n",
    "        \n",
    "        #P = np.random.binomial(1, 1.-prob, size=X_batch.shape[1]).astype(int)\n",
    "        #P = boolean(P)\n",
    "        #X_additional = X_batch[:,P]\n",
    "        \n",
    "        #b = X_batch.shape[1]\n",
    "        \n",
    "        #Reshape data, reflect left right, reshape back\n",
    "        aa=np.vstack(([np.fliplr(i.reshape(32,32,3)).flatten() for i in X_batch.T])).T\n",
    "        #Append reflected data/labels to originals\n",
    "        X_batch = np.hstack((X_batch,aa))\n",
    "        y_batch = np.tile(y_batch,2)\n",
    "        \n",
    "        \n",
    "        #Verify everything correct reflection and label:\n",
    "        #plt.figure()\n",
    "        #plt.imshow(X_batch.T[0].reshape(32,32,3))\n",
    "        #plt.show()\n",
    "        #print(y_batch[0])\n",
    "        #plt.figure()\n",
    "        #plt.imshow(X_batch.T[b].reshape(32,32,3))\n",
    "        #plt.show()\n",
    "        #print(y_batch[b])        \n",
    "        \n",
    "        \n",
    "        #Update the batch_size since now is potentilly larger\n",
    "        batch_size = X_batch.shape[1]\n",
    "        #print(batch_size)\n",
    "\n",
    "        return X_batch, y_batch, batch_size\n",
    "\n",
    "    \n",
    "    \n",
    "    def PreprocessInput(X_batch):\n",
    "        \"\"\"\n",
    "        Do standard scaling; or do whitening on the data.\n",
    "        \n",
    "        In training, just do on the individual batch.\n",
    "        But keep track of the statistics over all batches.\n",
    "        Then at test time, use full statistics.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def visualizeActivations(self,activations):\n",
    "        \"\"\"\n",
    "        Visualize activations for debugging\n",
    "        \"\"\"\n",
    "        N = len(activations)\n",
    "        r = int(np.ceil(np.sqrt(N)))\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        plt.title('Activations')\n",
    "        for i in range(N):\n",
    "            fig.add_subplot(r,r,i+1)\n",
    "            plt.hist(activations[i].flatten(),bins=50)\n",
    "            print('Activations', i, 'Mean', activations[i].flatten().mean(), 'SD', activations[i].flatten().std(), \\\n",
    "                  'Min', activations[i].flatten().min(), 'Max', activations[i].flatten().max())\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def visualizeWeightsAndGradients(self,gradients):\n",
    "        \"\"\"\n",
    "        Visualization tool for debugging\n",
    "        \"\"\"\n",
    "        \n",
    "        N = len(self.weights)\n",
    "        r = int(np.ceil(np.sqrt(N)))\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        plt.title('Weights')\n",
    "        for i in range(N):\n",
    "            fig.add_subplot(r,r,i+1)\n",
    "            plt.hist(self.weights[i].flatten(),bins=50)\n",
    "            print('Weights', i, 'Mean', self.weights[i].flatten().mean(), 'SD', self.weights[i].flatten().std())\n",
    "        plt.show()\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        plt.title('dW')\n",
    "        for i in range(N):\n",
    "            fig.add_subplot(r,r,i+1)\n",
    "            plt.hist(gradients['dW'][i].flatten(),bins=50)\n",
    "            print('dW', i, 'Mean', gradients['dW'][i].flatten().mean(), 'SD', gradients['dW'][i].flatten().std())\n",
    "        plt.show()        \n",
    "        \n",
    "        \n",
    "        #Just make plots of means / sds since easier to see than these histograms\n",
    "        \"\"\"\n",
    "        fig=plt.figure()\n",
    "        plt.title('Weights')\n",
    "        clist = ['r','g','b','k','c','m']\n",
    "        for i in range(N):\n",
    "            fig.plot(self.weights_means[i],,marker='o',color=clist[i],label='Loss')\n",
    "            print('Weights', i, 'Mean', self.weights[i].flatten().mean(), 'SD', self.weights[i].flatten().std())\n",
    "        plt.show()\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        plt.title('dW')\n",
    "        for i in range(N):\n",
    "            fig.add_subplot(r,r,i+1)\n",
    "            plt.hist(gradients['dW'][i].flatten())\n",
    "            print('dW', i, 'Mean', gradients['dW'][i].flatten().mean(), 'SD', gradients['dW'][i].flatten().std())\n",
    "        plt.show()      \n",
    "        \"\"\"\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Loss vs Iteration')\n",
    "        plt.plot(self.data_loss,marker='o',color='b',label='Data Loss')\n",
    "        if self.reg_lambda > 0.:\n",
    "            plt.plot(self.regularization_loss,marker='o',color='r',label='Regularization Loss')\n",
    "        plt.legend(numpoints=1)\n",
    "        #self.iterations_finished\n",
    "        plt.show()    \n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title('Accuracy vs Iteration (x10)')\n",
    "        plt.plot(self.training_accuracies,marker='o',color='g',label='Train')\n",
    "        plt.plot(self.validation_accuracies,marker='o',color='r',label='Validation')\n",
    "        plt.legend(numpoints=1)\n",
    "        #self.iterations_finished\n",
    "        plt.show()    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def affineForward(self, A, W, b):\n",
    "        \"\"\"\n",
    "        Forward pass for the affine layer.\n",
    "        :param A: input matrix, shape (L, S), where L is the number of hidden units in the previous layer and S is\n",
    "        the number of samples\n",
    "        :returns: the affine product WA + b, along with the cache required for the backward pass\n",
    "        \"\"\"\n",
    "        Z = np.matmul(W, A) + b\n",
    "        return Z\n",
    "        \n",
    "\n",
    "    def activationForward(self, A, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        Common interface to access all activation functions.\n",
    "        :param A: input to the activation function\n",
    "        :param prob: activation funciton to apply to A. Just \"relu\" for this assignment.\n",
    "        :returns: activation(A)\n",
    "        \"\"\" \n",
    "        return self.relu(A)\n",
    "\n",
    "\n",
    "    def relu(self, X):\n",
    "        A = np.maximum(0, X)\n",
    "        return A\n",
    "\n",
    "            \n",
    "    def dropout(self, A, prob):\n",
    "        \"\"\"\n",
    "        :param A: \n",
    "        :param prob: drop prob\n",
    "        :returns: tuple (A, M) \n",
    "            WHERE\n",
    "            A is matrix after applying dropout\n",
    "            M is dropout mask, used in the backward pass\n",
    "        \"\"\"\n",
    "        #rng = np.random.RandomState(123)\n",
    "        #M = rng.binomial(size=A.shape,\n",
    "        #                    n=1,\n",
    "        #                    p=1-prob)\n",
    "        \n",
    "        M = np.random.binomial(1, 1.-prob, size=A.shape)\n",
    "        #print(M)\n",
    "        \n",
    "        A *= M\n",
    "        return A, M\n",
    "\n",
    "    def forwardPropagation(self, X):\n",
    "        \"\"\"\n",
    "        Runs an input X through the neural network to compute activations\n",
    "        for all layers. Returns the output computed at the last layer along\n",
    "        with the cache required for backpropagation.\n",
    "        :returns: (tuple) AL, cache\n",
    "            WHERE \n",
    "            AL is activation of last layer\n",
    "            cache is cached values for each layer that\n",
    "                     are needed in further steps\n",
    "        \"\"\"\n",
    "        A = X\n",
    "        \n",
    "\n",
    "        cache = {\n",
    "            'biases' : [],\n",
    "            'weights' : [],\n",
    "            'dropoutMasks' : [],\n",
    "            'affines' : [],\n",
    "            'activations' : [A]\n",
    "        }\n",
    "        \n",
    "        #After already done 1 iteration, reuse the weights and biases we learned:\n",
    "        if self.iterations_finished > 0:\n",
    "            cache['biases'] = self.biases\n",
    "            cache['weights'] = self.weights\n",
    "            #print(len(cache['weights']))\n",
    "            #print(cache['weights'][0].shape)\n",
    "            #print(cache['weights'][1].shape)\n",
    "            #print(cache['weights'][2].shape)\n",
    "        \n",
    "        #same for below random initialization of W and b, are they being overwritten?\n",
    "        \n",
    "        for layer in range(1,self.num_layers):\n",
    "            #On 1st training iteration only, randomly initialize weights and biases:\n",
    "            if self.iterations_finished==0:\n",
    "                #Try Xavier-Glorot initialization [http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf]:\n",
    "                SD_glorot = np.sqrt(2. / (self.parameters['layerDimensions'][layer]+self.parameters['layerDimensions'][layer - 1]))\n",
    "                #Try MSRA initialization [https://arxiv.org/pdf/1502.01852.pdf]:\n",
    "                SD_MSRA = np.sqrt(2. / self.parameters['layerDimensions'][layer - 1])\n",
    "                #SD = SD_MSRA\n",
    "                #SD = SD_glorot\n",
    "                SD = .01\n",
    "                W = np.random.normal(0., SD, size=(self.parameters['layerDimensions'][layer], self.parameters['layerDimensions'][layer - 1]))\n",
    "                b = np.zeros(shape=(self.parameters['layerDimensions'][layer], 1))\n",
    "            else:\n",
    "                W = cache['weights'][layer-1]\n",
    "                b = cache['biases'][layer-1]\n",
    "            Z= self.affineForward(A, W, b)\n",
    "            \n",
    "            #So relu not applied to last layer (index self.num_layers-1):\n",
    "            #(Also we don't do ReLU onqt layer, but that's already taken \n",
    "            #care of because we do range(1,...) )\n",
    "            A = self.activationForward(Z) if layer!=self.num_layers-1 else Z\n",
    "            \n",
    "            if self.drop_prob > 0:\n",
    "                A, M = self.dropout(A,self.drop_prob)\n",
    "                cache['dropoutMasks'].append(M)\n",
    "            cache['affines'].append(Z)\n",
    "            cache['activations'].append(A)\n",
    "            \n",
    "            if self.iterations_finished==0:\n",
    "                cache['weights'].append(W)\n",
    "                cache['biases'].append(b)    \n",
    "\n",
    "        AL = A\n",
    "        return AL, cache\n",
    "    \n",
    "    def costFunction(self, AL, y, cache):\n",
    "        \"\"\"\n",
    "        :param AL: Activation of last layer, shape (num_classes, S)\n",
    "        :param y: labels, shape (S)\n",
    "        :param self.reg_lambda: regularization parameter\n",
    "        :returns cost, dAL: A scalar denoting cost and the gradient of cost\n",
    "        \"\"\"\n",
    "\n",
    "        epsilon = 10e-9 #10e-5 #10e-9 #Since taking logs of very small numbers is giving infs\n",
    "        S = y.size\n",
    "        \n",
    "        #Get softmax cost per sample:\n",
    "        #(both numerators and denominators are length S vectors)\n",
    "        #denominators = np.exp(AL).sum(axis=0)\n",
    "        #numerators = np.array([np.exp(AL[y[i]-1,i]) for i in range(S)])#-1 is assuming class labels start at 1. If they start at 0, get rid of -1.\n",
    "        #Actually will end up needing for gradients so just do as below...\n",
    "        \n",
    "        #print(AL)\n",
    "        #print(AL.min())\n",
    "        #print(AL.max())\n",
    "        \n",
    "        #print(np.exp(AL))\n",
    "        #print(np.exp(AL).min())\n",
    "        #print(np.exp(AL).max())\n",
    "        \n",
    "        \n",
    "        #Original, no clipping\n",
    "        #softmax_out = np.exp(AL)/(np.exp(AL).sum(axis=0)+epsilon)\n",
    "        \n",
    "        #Nan to num cliping:\n",
    "        softmax_out = np.nan_to_num(np.exp(AL))/(np.nan_to_num(np.exp(AL).sum(axis=0))+epsilon)\n",
    "        \n",
    "        #if 0's in softmax out, will get infs in cost, so clip to epsilon\n",
    "        softmax_out = softmax_out.clip(min=10e-20)\n",
    "        \n",
    "        #Need to know if there are nans/infs:\n",
    "        if DEBUG:\n",
    "            #nans_present = np.isnan(np.exp(AL)).any()\n",
    "            #infs_present = np.isinf(np.exp(AL)).any()\n",
    "            #if nans_present:\n",
    "            #    raise ValueError('nans in exp(AL)')\n",
    "            #if infs_present:\n",
    "            #    raise ValueError('infs in exp(AL)')\n",
    "            if np.isnan(softmax_out).any():\n",
    "                raise ValueError('nans in softmax function')\n",
    "            if np.isinf(softmax_out).any():\n",
    "                raise ValueError('infs in softmax function')\n",
    "            if (softmax_out==0.).any():\n",
    "                raise ValueError('zeros in softmax function')\n",
    "                \n",
    "\n",
    "                \n",
    "        #Manual clipping\n",
    "        #max_val = 10e3\n",
    "        #softmax_out = np.exp(AL).clip(0.,max_val)/(np.exp(AL).clip(0.,max_val).sum(axis=0)+epsilon)\n",
    "        \n",
    "        #print(softmax_out)\n",
    "        #print(softmax_out.min())\n",
    "        #print(softmax_out.max())\n",
    "\n",
    "        #Now get the cross-entropy / log-loss of this softmax:\n",
    "        #cost is the average over all samples\n",
    "        #cost = (-1./S)*np.nansum(np.log(softmax_out))#+epsilon)) #Should deal with nans, but for now just use nansum...\n",
    "        cost = (-1./S)*np.sum(np.log(softmax_out))\n",
    "        self.data_loss += [cost]\n",
    "        \n",
    "        #Need to know if there are nans/infs:\n",
    "        #With the nan/inf/0 handling above, there should never be any problems with cost function\n",
    "        #unless there is overflow in log function:\n",
    "        if DEBUG:\n",
    "            nans_present = np.isnan(np.log(softmax_out)).any()\n",
    "            infs_present = np.isinf(np.log(softmax_out)).any()\n",
    "            if nans_present:\n",
    "                raise ValueError('nans in cost function')\n",
    "            if infs_present:\n",
    "                raise ValueError('infs in cost function')\n",
    "                \n",
    "                \n",
    "        \n",
    "        #Also get the regularization cost:\n",
    "        if self.reg_lambda > 0.:\n",
    "            # add regularization\n",
    "            #If want to do other Lp norms as easy bonus:\n",
    "            #in init: self.reg_p_norm = 2#int p for p-norm regularization\n",
    "            #FOr now just using L2 norm:\n",
    "            #||W||^2\n",
    "            reg_cost = self.reg_lambda*np.array([np.sum(i.flatten()**2) for i in cache['weights']]).sum()\n",
    "            #print(reg_cost)\n",
    "            #print(cost)\n",
    "            cost += reg_cost\n",
    "            self.regularization_loss += [reg_cost]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # gradient of cost\n",
    "        #gradient through cross entropy, then sigmoid, turns out to be:\n",
    "        #for a single trainign example:\n",
    "        #dAL_i = sigmoid(z_i) - I(class==i);\n",
    "        #when go over all training batch examples, \n",
    "        #take average over axis 1. Is just sigmoid out array, with certain elements -1.\n",
    "        #Those elements are the ones corresponding to correct class label, for a given\n",
    "        #training example:\n",
    "        softmax_out[y,np.arange(S)] -= 1.\n",
    "        #Sum over axis 1 and then scale by S, i.e. take mean over samples:\n",
    "        #dAL = softmax_out.mean(axis=1)#actually since using 2D dropout mask,\n",
    "        #don't do the averaging now. Leave as 2D matrix with axis1 size = S, the number of samples\n",
    "        dAL = softmax_out\n",
    "        \n",
    "        #Since we don't use ReLU on last layer and treat it \n",
    "        #manually in this function by feeding it through softmax layer,\n",
    "        #get rid of last layer activation here since we basically bypass \n",
    "        #the gradient calculation for this last layer and do it separately.\n",
    "        #THen in the layers before this last one, can treat as usual.\n",
    "        _ = cache['activations'].pop()\n",
    "        #Same thing for dropout mask, if doing dropout:\n",
    "        if self.drop_prob > 0.:\n",
    "            _ = cache['dropoutMasks'].pop()\n",
    "        \n",
    "        return cost, dAL\n",
    "\n",
    "    \n",
    "    def affineBackward(self, dA_prev, cache, layer):\n",
    "        \"\"\"\n",
    "        Backward pass for the affine layer.\n",
    "        :param dA_prev: gradient from the next layer.\n",
    "        :param cache: cache returned in affineForward\n",
    "        :layer : since you need to multiply by weights/biases\n",
    "        :returns dA: gradient on the input to this layer\n",
    "                 dW: gradient on the weights\n",
    "                 db: gradient on the bias\n",
    "        \"\"\"\n",
    "        \n",
    "        #print('layer',layer)\n",
    "        \n",
    "        S = cache['activations'][0].shape[1]\n",
    "        \n",
    "        #Use the derivative from the later layer\n",
    "        #[\"previous\" since goign in reverse]:\n",
    "        #dA_prev\n",
    "        \n",
    "        W = cache['weights'][layer-1]\n",
    "        dA = np.dot(W.T,dA_prev)\n",
    "        #print(dA.shape)\n",
    "\n",
    "        #If doing dropout:\n",
    "        if self.drop_prob > 0.:\n",
    "            #Sropout not used directly on input layer, even if mask is generated for it.\n",
    "            if layer > 1:\n",
    "                dA = self.dropout_backward(dA, cache)\n",
    "        dA = self.activationBackward(dA, cache, None, activation=\"relu\")\n",
    "        \n",
    "        #Repeat dA_prev since have S samples:\n",
    "        #dW = np.dot(np.repeat(dA_prev.reshape((dA_prev.size,1)),S,axis=1),cache['activations'][-1].T)\n",
    "        #Since dropout mask, just keep dA_prev in 2D [don't average over samples]\n",
    "        dW = np.dot(dA_prev,cache['activations'][-1].T)\n",
    "        #print(dW)\n",
    "        #print(dW.min(),dW.max())\n",
    "        #print(dW.shape)#(10,100)\n",
    "\n",
    "        \n",
    "        #If regularized, also add in gradients from reg cost:\n",
    "        if self.reg_lambda > 0:\n",
    "            dW += self.reg_lambda*W #For now assuming only L2 reg.\n",
    "        \n",
    "        #d_output / db = I(if i)\n",
    "        db = np.ones(cache['biases'][layer-1].shape)\n",
    "        \n",
    "        \n",
    "        #Now that done using the activations, get rid of them \n",
    "        #so indexing correct for next iterations:\n",
    "        cache['activations'].pop()\n",
    "        #print(len(cache['activations']))\n",
    "        #print(cache['activations'][0].shape)\n",
    "\n",
    "        return dA, dW, db\n",
    "\n",
    "    \n",
    "    \n",
    "    def activationBackward(self, dA, cache, layer, activation=\"relu\"):\n",
    "        \"\"\"\n",
    "        Interface to call backward on activation functions.\n",
    "        In this case, it's just relu. \n",
    "        \"\"\"\n",
    "        cached_x = cache['activations'][-1]\n",
    "        return self.relu_derivative(dA, cached_x)\n",
    "\n",
    "        \n",
    "    def relu_derivative(self, dx, cached_x):\n",
    "\n",
    "        #S = cached_x.shape[1]\n",
    "        #Repeat dx since have S samples:\n",
    "        #dx = np.repeat(dx.reshape((dx.size,1)),S,axis=1)\n",
    "        \n",
    "        #In positive region, dx=1; in negative region = 0:\n",
    "        dx = np.ones(cached_x.shape)*dx\n",
    "        #Mask the negative region to 0.\n",
    "        dx[cached_x <= 0.] = 0.\n",
    "        #Could treat the exact ==0. case differently but to precision will never get ==0.\n",
    "        \n",
    "        #Average over axis 1 [averaged over samples]\n",
    "        #dx = dx.mean(axis=1)#No longer do this since dropout mask\n",
    "        return dx\n",
    "\n",
    "    \n",
    "    def dropout_backward(self, dA, cache):\n",
    "        dA *= cache['dropoutMasks'].pop()\n",
    "        return dA\n",
    "\n",
    "    def backPropagation(self, dAL, Y, cache):\n",
    "        \"\"\"\n",
    "        Run backpropagation to compute gradients on all paramters in the model\n",
    "        :param dAL: gradient on the last layer of the network. Returned by the cost function.\n",
    "        :param Y: labels\n",
    "        :param cache: cached values during forwardprop\n",
    "        :returns gradients: dW and db for each weight/bias\n",
    "        \"\"\"\n",
    "        gradients = {\n",
    "            'dW' : [],\n",
    "            'db' : []\n",
    "         }\n",
    "        \n",
    "        \n",
    "        dA = dAL\n",
    "        for layer in range(self.num_layers-1):\n",
    "            dA, dW, db = self.affineBackward(dA,cache,self.num_layers-layer-1)\n",
    "            gradients['dW'].append(dW) \n",
    "            gradients['db'].append(db) \n",
    "            \n",
    "            #Was easier to just put inside affineBackward...\n",
    "            #if self.drop_prob > 0:\n",
    "            #    #If not working on the input layer (don't use dropout on it):\n",
    "            #    if layer < self.num_layers-2 #-2 since: \n",
    "            #        self.dropout_backward(dA,cache)\n",
    "           \n",
    "        # TODO    \n",
    "        #if self.reg_lambda > 0:\n",
    "            # add gradients from L2 regularization to each dW\n",
    "            #GK: I'm just adding them to dAL in the costfunction so should be ok w/o this here\n",
    "        gradients['dW'].reverse()\n",
    "        gradients['db'].reverse() \n",
    "        return gradients\n",
    "\n",
    "\n",
    "    def updateParameters(self, gradients, alpha, cache):\n",
    "        \"\"\"\n",
    "        :param gradients: gradients for each weight/bias\n",
    "        :param alpha: step size for gradient descent \n",
    "        \n",
    "        cache: to update the parameters we are learning [weights and biases],\n",
    "        those values also need to be passed in.\n",
    "        \"\"\"\n",
    "        \n",
    "        #Weights\n",
    "        #print(cache['weights'][0])\n",
    "        #print(gradients['dW'][0].min())\n",
    "        #print(gradients['dW'][0].max())\n",
    "        cache['weights'] = [cache['weights'][i]  - alpha*gradients['dW'][i] for i in range(len(cache['weights']))] \n",
    "        #print(cache['weights'][0])\n",
    "        #print(cache['weights'][0].max())\n",
    "        #print(cache['weights'][0].min())\n",
    "\n",
    "        #biases\n",
    "        #print(cache['biases'][0])\n",
    "        cache['biases'] = [cache['biases'][i]  - alpha*gradients['db'][i] for i in range(len(cache['biases']))] \n",
    "        #print(cache['biases'][0])\n",
    "    \n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions for each sample\n",
    "        \"\"\"\n",
    "        \n",
    "        AL, _ = self.forwardPropagation(X)\n",
    "        \n",
    "        #Get probability per class per sample, then take argmax:\n",
    "        #Technically don't need to go through softmax calculations, etc. since max here is max after too.\n",
    "        #SO just get argmax for each sample:\n",
    "        y_pred = np.argmax(AL,axis=0)\n",
    "\n",
    "        if DEBUG:\n",
    "            print(y_pred)\n",
    "            print(np.bincount(y_pred))\n",
    "        #y_pred = [100, 200, 300]\n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "    def get_batch(self, X, y, batch_size):\n",
    "        \"\"\"\n",
    "        Return minibatch of samples and labels\n",
    "        \n",
    "        :param X, y: samples and corresponding labels\n",
    "        :parma batch_size: minibatch size\n",
    "        :returns: (tuple) X_batch, y_batch\n",
    "        \"\"\"\n",
    "        selector = np.random.choice(np.arange(np.size(y)), batch_size, replace=False)\n",
    "        return X[:, selector], y[selector]\n",
    "\n",
    "    def train(self, X, y, iters=1000, alpha=0.0001, batch_size=100, print_every=100):\n",
    "        \"\"\"\n",
    "        :param X: input samples, each column is a sample\n",
    "        :param y: labels for input samples, y.shape[0] must equal X.shape[1]\n",
    "        :param iters: number of training iterations\n",
    "        :param alpha: step size for gradient descent\n",
    "        :param batch_size: number of samples in a minibatch\n",
    "        :param print_every: no. of iterations to print debug info after\n",
    "        \"\"\"\n",
    "        \n",
    "        #Split training data into training and validation set (90/10 split):\n",
    "        train_inds = np.random.choice(X.shape[1],int(X.shape[1]*.90),replace=False)\n",
    "        validation_inds = np.setdiff1d(np.arange(X.shape[1]),train_inds)\n",
    "        X_training = X[:,train_inds]\n",
    "        y_training = y[train_inds]\n",
    "        X_validation = X[:,validation_inds]\n",
    "        y_validation = y[validation_inds]\n",
    "        #print(X_training.shape, y_training.shape, X_validation.shape, y_validation.shape)\n",
    "        \n",
    "        \n",
    "        #Do training iterations\n",
    "        for i in range(0, iters):\n",
    "            # get minibatch\n",
    "            X_batch, y_batch = self.get_batch(X_training, y_training, batch_size)\n",
    "            \n",
    "            #Left right reflection as form of data augmentation\n",
    "            if self.do_reflection:\n",
    "                X_batch, y_batch, batch_size = self.LeftRightReflection(X_batch, y_batch, prob_reflect=.5)\n",
    "                #print(X_batch.shape, y_batch.shape, batch_size)\n",
    "            \n",
    "            \n",
    "            # forward prop\n",
    "            AL, cache = self.forwardPropagation(X_batch)\n",
    "            \n",
    "            #For debugging, look at activations [do here before popped off in backprop]\n",
    "            if DEBUG and i % 100 == 0:\n",
    "                self.visualizeActivations(cache['activations'])\n",
    "\n",
    "            # compute loss\n",
    "            cost, dAL = self.costFunction(AL, y_batch, cache)\n",
    "            #print('cost',cost)\n",
    "            \n",
    "            # compute gradients\n",
    "            gradients = self.backPropagation(dAL, y_batch, cache)\n",
    "            #print('gradients',gradients,len(gradients['dW']),gradients['dW'][0].shape)\n",
    "\n",
    "            # update weights and biases based on gradient\n",
    "            #print(self.iterations_finished)\n",
    "            #print('alpha',alpha)\n",
    "            #This learning rate alpha will decay step exponentially [every K iters, multiply by 0<gamma<=1]\n",
    "            self.updateParameters(gradients, alpha, cache) #will update weights + biases in place\n",
    "\n",
    "            \n",
    "            #Store the weights and biases that were just updated: \n",
    "            self.weights = cache['weights']\n",
    "            self.biases = cache['biases']\n",
    "            #print(len(self.weights))\n",
    "            #print(len(self.biases))\n",
    "            #print(self.weights[0].shape)\n",
    "            #print(self.biases[0].shape)\n",
    "            \n",
    "            \n",
    "            #Iteration counter\n",
    "            self.iterations_finished += 1\n",
    "            \n",
    "            #Lower the learning rate every K iterations.\n",
    "            #Just use an exponential decay here: alpha' = alpha*gamma^(floor(i/K))\n",
    "            if self.iterations_finished % self.K_iters_alpha_drop == 0:\n",
    "                alpha *= self.gamma #decaying stepwise exponentially\n",
    "            \n",
    "            \n",
    "            if i % print_every == 0:\n",
    "                #Training set accruacy:\n",
    "                y_batch_predicted = self.predict(X_batch)\n",
    "                train_accuracy = (y_batch_predicted==y_batch).sum()/np.float(batch_size)\n",
    "                #Validation set accuracy:\n",
    "                y_validation_predicted = self.predict(X_validation)\n",
    "                validation_accuracy = (y_validation_predicted==y_validation).sum()/np.float(y_validation.size)\n",
    "                print('cost: {0}, train accuracy: {1}, validation accuracy: {2}'.format(\n",
    "                    cost, train_accuracy, validation_accuracy))\n",
    "                \n",
    "                self.training_accuracies += [train_accuracy]\n",
    "                self.validation_accuracies += [validation_accuracy]\n",
    "                \n",
    "                \n",
    "                print('iterations finished:', self.iterations_finished, 'alpha:', alpha, 'reg. lambda:', self.reg_lambda)\n",
    "                print('\\n')\n",
    "                \n",
    "                \n",
    "            \n",
    "            #For debugging, look at weights and gradients on weights\n",
    "            if DEBUG and i % 100 == 0:\n",
    "                self.visualizeWeightsAndGradients(gradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions, DO NOT modify this\n",
    "\n",
    "def get_img_array(path):\n",
    "    \"\"\"\n",
    "    Given path of image, returns it's numpy array\n",
    "    \"\"\"\n",
    "    return scipy.misc.imread(path)\n",
    "\n",
    "def get_files(folder):\n",
    "    \"\"\"\n",
    "    Given path to folder, returns list of files in it\n",
    "    \"\"\"\n",
    "    filenames = [file for file in glob.glob(folder+'*/*')]\n",
    "    filenames.sort()\n",
    "    return filenames\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions to load data, DO NOT change these\n",
    "\n",
    "def get_labels(folder, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    y = []\n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "    return np.array(y)\n",
    "\n",
    "def one_hot(y, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts each label index in y to vector with one_hot encoding\n",
    "    \"\"\"\n",
    "    y_one_hot = np.zeros((y.shape[0], num_classes))\n",
    "    y_one_hot[y] = 1\n",
    "    return y_one_hot.T\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "    return id2label, label2id\n",
    "\n",
    "def get_images(folder):\n",
    "    \"\"\"\n",
    "    returns numpy array of all samples in folder\n",
    "    each column is a sample resized to 30x30 and flattened\n",
    "    \"\"\"\n",
    "    files = get_files(folder)\n",
    "    images = []\n",
    "    count = 0\n",
    "    \n",
    "    for f in files:\n",
    "        count += 1\n",
    "        if count % 10000 == 0:\n",
    "            print(\"Loaded {}/{}\".format(count,len(files)))\n",
    "        img_arr = get_img_array(f)\n",
    "        img_arr = img_arr.flatten() / 255.0\n",
    "        images.append(img_arr)\n",
    "    X = np.column_stack(images)\n",
    "\n",
    "    return X\n",
    "\n",
    "def get_train_data(data_root_path):\n",
    "    \"\"\"\n",
    "    Return X and y\n",
    "    \"\"\"\n",
    "    train_data_path = data_root_path + 'train'\n",
    "    id2label, label2id = get_label_mapping(data_root_path+'labels.txt')\n",
    "    print(label2id)\n",
    "    X = get_images(train_data_path)\n",
    "    y = get_labels(train_data_path, label2id)\n",
    "    return X, y\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n",
      "Loaded 10000/50000\n",
      "Loaded 20000/50000\n",
      "Loaded 30000/50000\n",
      "Loaded 40000/50000\n",
      "Loaded 50000/50000\n",
      "Loaded 10000/10000\n",
      "Data loading done\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_root_path = 'cifar10-hw1/'\n",
    "X_train, y_train = get_train_data(data_root_path) # this may take a few minutes\n",
    "X_test = get_images(data_root_path + 'test')\n",
    "print('Data loading done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "#### Simple fully-connected deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations 0 Mean 0.447466681985 SD 0.247665377336 Min 0.0 Max 1.0\n",
      "Activations 1 Mean 0.121118657848 SD 0.178459020293 Min 0.0 Max 1.12445440172\n",
      "Activations 2 Mean -0.00499931667137 SD 0.0209162311326 Min -0.0687801911128 Max 0.0565036867816\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203a65d4588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[ 0 99  0  0  0  0  0  0  0  1]\n",
      "[1 1 1 ..., 1 1 1]\n",
      "[  21 4906    1    0    0    2    0    0    2   68]\n",
      "cost: 23.02801299483487, train accuracy: 0.13, validation accuracy: 0.102\n",
      "iterations finished: 1 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "Weights 0 Mean 5.20842528099e-06 SD 0.00999915582673\n",
      "Weights 1 Mean -0.000111101196103 SD 0.0099163639617\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndowdHdI16a8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203cf32c0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dW 0 Mean 0.00188318209763 SD 0.0362688980176\n",
      "dW 1 Mean -1.21727971703e-09 SD 0.647012331378\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBYaIiARRYIiISBAFhoiIBFFgiIhIkP8PTIzIn7YClGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20492bcb2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF5NJREFUeJzt3X+Q1PWd5/Hni2EMImO4yIDCgKMJtxc0MJI5xBC9DexZ\nZM6EK025UZaEJLeclZBIycUjcrer2SUpQyKpjV4pF82tZjzOnJjzEI140S29RNaBG3ABFaQGGCTr\nhKyKiz/48b4/+jvZduyZ6ZnumZ7h83pUdXV/P9/P59vvT3fx4jufb8+0IgIzM0vHiEoXYGZmg8vB\nb2aWGAe/mVliHPxmZolx8JuZJcbBb2aWGAe/2TAhaYqkNyVVVboWG94c/DZoJLVJ+qNK19FfkkLS\nR7LHN0v66QA/33ter4jYHxFjIuLEQD6vnfoc/GYVIGlkpWuwdDn4bUiQ9KeS9kj6naSHJU3M2iVp\njaRXJb0h6XlJF2b7miTtlHRE0kFJ/6HAcT8g6bXOMVlbraS3JI2XNE7ShqzP7yQ9LanHfxeS5gM3\nAX+cLb1sy9o/KOluSYeyev6yc1lG0mJJ/zeby2HgZkkflvRLSYcl/VZSs6SxWf/7gCnA/86e40ZJ\n9dlPHSOzPhOz1+p32Wv3p3k13izpAUn3Zq/PDkmNJb1Jdspw8FvFSZoLfBe4GjgH2Aesy3ZfDlwG\n/HPgg1mfw9m+u4F/HxE1wIXAL7seOyLeAdYD1+Q1Xw38TUS8CiwH2oFaYAK5QO/x75hExGPAd4D/\nkS29zMh2/TfgOPAR4KKs9n+XN/RiYG/2PKsAZfOeCHwUmAzcnD3HImA/8JnsOb5XoJR1We0Tgc8B\n38ley06fzfqMBR4Gbu9pXpYOB78NBQuBeyJiaxbU3wIukVQPHANqgH8BKCJ2RcShbNwxYJqkMyPi\nHyJiazfHvx/4fN72tVlb5zHOAc6NiGMR8XT04w9YSZoANAHLIuIfs/9U1nR53lci4kcRcTwi3oqI\nPRGxKSLeiYgO4DbgXxX5fJOBOcB/jIi3I6IV+DHwhbxuz0TExuyawH3AjAKHsgQ5+G0omEjuLB+A\niHiT3Fn9pIj4Jbkz1TuAVyWtlXRm1vUqcmG7T9LfSLqkm+M/CYyWdHH2n0kD8FC2bzWwB3hc0l5J\nK/o5h3OBauBQtmz0GnAXMD6vz4H8AZImSFqXLQu9AfwUGFfk800EfhcRR/La9gGT8rZ/k/f4KDDK\n1xYMHPw2NLxCLjgBkHQGcBZwECAi/ioiPg5MI7fk882s/bmIWEAuXH8OPFDo4NkZ7wPklnuuATZ0\nBmZEHImI5RFxPrmlkRskzSui5q4/FRwA3gHGRcTY7HZmRFzQw5jvZG0fi4gzgT8ht/zTXf98rwAf\nklST1zaF7DUz64mD3wZbtaRRebeRwH8HviSpQdIHyAXi5ohok/QvszP1auAfgbeBk5JOk7RQ0gcj\n4hjwBnCyh+e9H/hjcstKncs8SLpC0kckCXgdONHLcTr9PVDfeSE4W356HPiBpDMljcgu3va0dFMD\nvAm8LmkS2X9oXZ7j/EIDI+IA8Cvgu9nrOB34CrmfGsx65OC3wbYReCvvdnNEPAH8Z+BB4BDwYf5p\nbfxM4L8C/0BuKeMwueUZgEVAW7ZMch25UC8oIjaT+49jIvBo3q6pwBPkAvjXwH+JiCeLmMfPsvvD\nkjqvLXwBOA3YmdX7P8ldP+jOLcBMcv/hPELuInS+7wL/KVs6et8nlsj99FJP7uz/IeDPs9fSrEfy\nF7GYmaXFZ/xmZolx8JuZJcbBb2aWGAe/mVlihuQvc4wbNy7q6+srXYaZ2bCxZcuW30ZEbTF9h2Tw\n19fX09LSUukyzMyGDUn7eu+V46UeM7PEOPjNzBLj4DczS8yQXOM3s1PHsWPHaG9v5+233650KaeE\nUaNGUVdXR3V1db+P4eA3swHV3t5OTU0N9fX15P4WnvVXRHD48GHa29s577zz+n0cL/WY2YB6++23\nOeussxz6ZSCJs846q+Sfnhz8ZjbgHPrlU47X0sFvZpYYB7+ZnfKqqqpoaGjgggsuYMaMGfzgBz/g\n5Mmev2+nra2N+++/v8c+hYwZM6a/ZQ4aB7+ZDSnNzVBfDyNG5O6bm0s/5umnn05rays7duxg06ZN\nPProo9xyyy09julv8A8HDn4zGzKam2HJEti3DyJy90uWlCf8O40fP561a9dy++23ExG0tbVx6aWX\nMnPmTGbOnMmvfvUrAFasWMHTTz9NQ0MDa9as6bZfMdra2pg7dy7Tp09n3rx57N+/H4Cf/exnXHjh\nhcyYMYPLLrsMgB07djBr1iwaGhqYPn06u3fvLt/kM0PyG7gaGxvDf6vH7NSwa9cuPvrRjwKwbBm0\ntnbf99ln4Z133t/+gQ/A7NmFxzQ0wA9/2HMNY8aM4c0333xP29ixY3nxxRepqalhxIgRjBo1it27\nd3PNNdfQ0tLCU089xfe//302bNgAwNGjRwv2K+a5PvOZz/C5z32OL37xi9xzzz08/PDD/PznP+dj\nH/sYjz32GJMmTeK1115j7NixfP3rX2f27NksXLiQd999lxMnTnD66ae/53j5r2knSVsiorHnVyLH\nn+M3syGjUOj31F4Ox44dY+nSpbS2tlJVVcVLL71UUr9Cfv3rX7N+fe4rlRctWsSNN94IwJw5c1i8\neDFXX301V155JQCXXHIJq1ator29nSuvvJKpU6eWOMP3c/Cb2aDp7cy8vj63vNPVuefCU0+Vr469\ne/dSVVXF+PHjueWWW5gwYQLbtm3j5MmTjBo1quCYNWvWFNWvL+688042b97MI488wsc//nG2bNnC\ntddey8UXX8wjjzxCU1MTd911F3Pnzi35ufJ5jd/MhoxVq2D06Pe2jR6day+Xjo4OrrvuOpYuXYok\nXn/9dc455xxGjBjBfffdx4kTJwCoqanhyJEjvx/XXb9ifOITn2DdunUANDc3c+mllwLw8ssvc/HF\nF/Ptb3+b2tpaDhw4wN69ezn//PP5xje+wYIFC9i+fXv5Jp/xGb+ZDRkLF+buV66E/fthypRc6He2\n99dbb71FQ0MDx44dY+TIkSxatIgbbrgBgK9+9atcddVV3HvvvcyfP58zzjgDgOnTp1NVVcWMGTNY\nvHhxt/26Onr0KHV1db/fvuGGG/jRj37El770JVavXk1tbS0/+clPAPjmN7/J7t27iQjmzZvHjBkz\nuPXWW7nvvvuorq7m7LPP5qabbipt8gX44q6ZDahCFyKtNKVe3PVSj5lZYhz8ZmaJcfCb2YAbikvK\nw1U5Xsteg1/SZElPStopaYek67vsXy4pJI3rZvx8SS9K2iNpRckVm9mwMmrUKA4fPuzwL4POv8df\n6kdJi/lUz3FgeURslVQDbJG0KSJ2SpoMXA7sLzRQUhVwB/CvgXbgOUkPR8TOkqo2s2Gjrq6O9vZ2\nOjo6Kl3KKaHzG7hK0WvwR8Qh4FD2+IikXcAkYCewBrgR+F/dDJ8F7ImIvQCS1gELsrFmloDq6uqS\nvi3Kyq9Pa/yS6oGLgM2SFgAHI2JbD0MmAQfyttuzNjMzq5Cif4FL0hjgQWAZueWfm8gt85SFpCXA\nEoApU6aU67BmZtZFUWf8kqrJhX5zRKwHPgycB2yT1AbUAVslnd1l6EFgct52Xdb2PhGxNiIaI6Kx\ntra2b7MwM7Oi9XrGr9wXPN4N7IqI2wAi4nlgfF6fNqAxIn7bZfhzwFRJ55EL/M8D15andDMz649i\nzvjnAIuAuZJas1tTd50lTZS0ESAijgNLgV8Au4AHImJHGeo2M7N+KuZTPc8APX6te0TU5z1+BWjK\n294IbOx/iWZmVk7+zV0zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4z\ns8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPf\nzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPg\nNzNLjIPfzCwxDn4zs8Q4+M3MEtNr8EuaLOlJSTsl7ZB0fdb+F5K2S2qV9Likid2Mb5P0fNavpdwT\nMDOzvinmjP84sDwipgGzga9JmgasjojpEdEAbAD+rIdjfCoiGiKisfSSzcysFL0Gf0Qcioit2eMj\nwC5gUkS8kdftDCAGpkQzMyunkX3pLKkeuAjYnG2vAr4AvA58qpthATwh6QRwV0Ss7W+xZmZWuqIv\n7koaAzwILOs824+IlRExGWgGlnYz9JPZctCnyS0TXdbN8ZdIapHU0tHR0adJmJlZ8YoKfknV5EK/\nOSLWF+jSDFxVaGxEHMzuXwUeAmZ1029tRDRGRGNtbW0xZZmZWT8U86keAXcDuyLitrz2qXndFgAv\nFBh7hqSazsfA5cDflVq0mZn1XzFr/HOARcDzklqztpuAr0j6A+AksA+4DiD7WOePI6IJmAA8lPu/\ng5HA/RHxWHmnYGZmfdFr8EfEM4AK7NrYTf9XgKbs8V5gRikFmplZefk3d83MEuPgNzNLjIPfzCwx\nDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNL\njIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M3M\nEuPgNzNLjIPfzCwxDn4zs8Q4+M3MEuPgNzNLjIPfzCwxDn4zs8Q4+M2K0NwM9fUwYkTuvrm50hWZ\n9d/IShdgNtQ1N8OSJXD0aG57377cNsDChZWry6y/ej3jlzRZ0pOSdkraIen6rP0vJG2X1CrpcUkT\nuxk/X9KLkvZIWlHuCZgNtJUr/yn0Ox09mms3G46KWeo5DiyPiGnAbOBrkqYBqyNiekQ0ABuAP+s6\nUFIVcAfwaWAacE021mzY2L+/b+1mQ12vwR8RhyJia/b4CLALmBQRb+R1OwOIAsNnAXsiYm9EvAus\nAxaUXrbZ4JkypW/tZkNdny7uSqoHLgI2Z9urJB0AFlLgjB+YBBzI227P2gode4mkFkktHR0dfSnL\nbECtWgWjR7+3bfToXLvZcFR08EsaAzwILOs824+IlRExGWgGlpZSSESsjYjGiGisra0t5VBmZbVw\nIaxdC+eeC1Lufu1aX9i14auoT/VIqiYX+s0Rsb5Al2ZgI/DnXdoPApPztuuyNrNhZeFCB72dOor5\nVI+Au4FdEXFbXvvUvG4LgBcKDH8OmCrpPEmnAZ8HHi6tZDMzK0UxZ/xzgEXA85Jas7abgK9I+gPg\nJLAPuA4g+1jnjyOiKSKOS1oK/AKoAu6JiB3lnoSZmRWv1+CPiGcAFdi1sZv+rwBNedsbu+trZmaD\nz3+ywcwsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjN\nzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+\nM7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD\n38wsMQ5+M7PE9Br8kiZLelLSTkk7JF2fta+W9IKk7ZIekjS2m/Ftkp6X1CqppdwTMDOzvinmjP84\nsDwipgGzga9JmgZsAi6MiOnAS8C3ejjGpyKiISIaS67YzMxK0mvwR8ShiNiaPT4C7AImRcTjEXE8\n6/YsUDdwZZqZWbn0aY1fUj1wEbC5y64vA492MyyAJyRtkbSkh2MvkdQiqaWjo6MvZZmZWR8UHfyS\nxgAPAssi4o289pXkloOauxn6yYhoAD5NbpnoskKdImJtRDRGRGNtbW3REzAzs74pKvglVZML/eaI\nWJ/Xvhi4AlgYEVFobEQczO5fBR4CZpVYs5mZlaCYT/UIuBvYFRG35bXPB24EPhsRR7sZe4akms7H\nwOXA35WjcDMz659izvjnAIuAudlHMlslNQG3AzXApqztTgBJEyVtzMZOAJ6RtA34W+CRiHis/NMw\nM7NijeytQ0Q8A6jAro0F2oiIV4Cm7PFeYEYpBZqZWXn5N3fNzBLj4DczS4yD38wsMQ5+M7PEOPjN\nzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+\nM7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD\n38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS0yvwS9psqQnJe2UtEPS9Vn7\nakkvSNou6SFJY7sZP1/Si5L2SFpR7gmYmVnfFHPGfxxYHhHTgNnA1yRNAzYBF0bEdOAl4FtdB0qq\nAu4APg1MA67JxpqZWYX0GvwRcSgitmaPjwC7gEkR8XhEHM+6PQvUFRg+C9gTEXsj4l1gHbCgPKWb\nmVl/9GmNX1I9cBGwucuuLwOPFhgyCTiQt92etRU69hJJLZJaOjo6+lKWmZn1QdHBL2kM8CCwLCLe\nyGtfSW45qLmUQiJibUQ0RkRjbW1tKYcyM7MejCymk6RqcqHfHBHr89oXA1cA8yIiCgw9CEzO267L\n2szMrEKK+VSPgLuBXRFxW177fOBG4LMRcbSb4c8BUyWdJ+k04PPAw6WXbWZm/VXMUs8cYBEwV1Jr\ndmsCbgdqgE1Z250AkiZK2giQXfxdCvyC3EXhByJix0BMxMzMitPrUk9EPAOowK6N3fR/BWjK297Y\nXV8zMxt8/s1dM7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4yD38wsMQ5+M7PEOPjN\nzBLj4DczS4yD38wsMQ5+M7PEOPjNzBLj4DczS4wKf2NiZUnqAPZVuo4+Ggf8ttJFDDLPOQ2e8/Bw\nbkQU9YXlQzL4hyNJLRHRWOk6BpPnnAbP+dTjpR4zs8Q4+M3MEuPgL5+1lS6gAjznNHjOpxiv8ZuZ\nJcZn/GZmiXHwm5klxsHfB5I+JGmTpN3Z/T/rpt98SS9K2iNpRYH9yyWFpHEDX3VpSp2zpNWSXpC0\nXdJDksYOXvXFK+I9k6S/yvZvlzSz2LFDVX/nLGmypCcl7ZS0Q9L1g199/5TyPmf7qyT9P0kbBq/q\nARARvhV5A74HrMgerwBuLdCnCngZOB84DdgGTMvbPxn4BblfUBtX6TkN9JyBy4GR2eNbC42v9K23\n9yzr0wQ8CgiYDWwuduxQvJU453OAmdnjGuClU33OeftvAO4HNlR6PqXcfMbfNwuAv84e/zXwbwv0\nmQXsiYi9EfEusC4b12kNcCMwXK6qlzTniHg8Io5n/Z4F6ga43v7o7T0j2743cp4Fxko6p8ixQ1G/\n5xwRhyJiK0BEHAF2AZMGs/h+KuV9RlId8G+AHw9m0QPBwd83EyLiUPb4N8CEAn0mAQfyttuzNiQt\nAA5GxLYBrbK8SppzF18mdzY11BRTf3d9ip37UFPKnH9PUj1wEbC57BWWX6lz/iG5k7aTA1XgYBlZ\n6QKGGklPAGcX2LUyfyMiQlLRZ+2SRgM3kVv6GFIGas5dnmMlcBxo7s94G3okjQEeBJZFxBuVrmcg\nSboCeDUitkj6w0rXUyoHfxcR8Ufd7ZP0950/6mY//r1aoNtBcuv4neqytg8D5wHbJHW2b5U0KyJ+\nU7YJ9MMAzrnzGIuBK4B5kS2UDjE91t9Ln+oixg5FpcwZSdXkQr85ItYPYJ3lVMqcrwI+K6kJGAWc\nKemnEfEnA1jvwKn0RYbhdANW894Lnd8r0GcksJdcyHdeQLqgQL82hsfF3ZLmDMwHdgK1lZ5LD3Ps\n9T0jt7abf9Hvb/vyfg+1W4lzFnAv8MNKz2Ow5tylzx8yzC/uVryA4XQDzgL+D7AbeAL4UNY+EdiY\n16+J3CcdXgZWdnOs4RL8Jc0Z2ENuzbQ1u91Z6Tl1M8/31Q9cB1yXPRZwR7b/eaCxL+/3ULz1d87A\nJ8l9OGF73vvaVOn5DPT7nHeMYR/8/pMNZmaJ8ad6zMwS4+A3M0uMg9/MLDEOfjOzxDj4zcwS4+A3\nM0uMg9/MLDH/H2C0XkVQN/LhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2049308c7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20492c1d7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 9 9 9 9 0 0 9 0 0 9 0 9 9 0 0 9 0 9 0 0 0 9 9 9 0 0 9 0 0 0 9 0 0\n",
      " 9 9 0 0 0 0 0 0 0 9 9 9 0 0 9 0 0 0 9 0 7 0 9 0 0 9 0 0 9 0 9 0 0 9 9 0 9\n",
      " 0 0 9 9 9 0 9 9 0 9 0 0 9 9 9 9 9 9 0 0 0 0 9 0 9 0]\n",
      "[56  0  0  0  0  0  0  1  0 43]\n",
      "[0 0 0 ..., 9 0 0]\n",
      "[2894    0   18    0    0    0    0   28   11 2049]\n",
      "cost: 23.044058883949848, train accuracy: 0.19, validation accuracy: 0.1502\n",
      "iterations finished: 11 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[8 8 5 5 5 0 5 8 5 8 5 5 5 8 8 8 8 5 5 5 5 5 5 5 8 5 5 5 8 5 8 5 5 5 8 0 5\n",
      " 8 8 8 8 5 0 8 5 5 5 5 5 5 5 5 8 5 5 5 5 5 5 8 5 5 5 8 8 5 5 5 5 8 5 8 5 8\n",
      " 8 5 5 8 5 8 5 5 8 8 8 8 5 5 5 8 9 5 8 5 5 8 5 5 8 8]\n",
      "[ 3  0  0  0  0 60  0  0 36  1]\n",
      "[5 8 8 ..., 8 5 8]\n",
      "[ 168    0    0    1    0 2574    0   15 1929  313]\n",
      "cost: 23.041358053423593, train accuracy: 0.2, validation accuracy: 0.1846\n",
      "iterations finished: 21 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[8 7 8 8 5 8 8 8 8 5 8 8 8 8 8 8 8 8 5 8 8 8 8 8 8 8 8 5 5 8 8 8 8 2 8 8 8\n",
      " 8 8 8 5 8 8 8 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 5 8 0 8 8 8\n",
      " 8 8 8 8 8 8 5 8 8 2 8 7 5 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "[ 1  0  2  0  0  9  0  3 85]\n",
      "[8 8 8 ..., 8 8 8]\n",
      "[  25    0  150    0    0  290    0  159 4376]\n",
      "cost: 23.21081937809272, train accuracy: 0.2, validation accuracy: 0.1222\n",
      "iterations finished: 31 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[9 0 5 6 6 6 8 8 8 8 6 6 8 9 6 5 8 9 0 9 0 6 2 6 5 9 8 8 0 8 8 8 5 9 9 0 6\n",
      " 8 0 8 8 6 8 8 8 9 8 8 8 0 5 9 6 0 6 0 8 8 6 6 6 6 8 8 6 8 8 8 9 8 8 6 9 9\n",
      " 8 8 8 0 6 8 6 6 8 6 6 8 8 8 8 5 8 8 6 9 8 9 2 8 8 8]\n",
      "[10  0  2  0  0  6 24  0 44 14]\n",
      "[6 8 8 ..., 8 6 8]\n",
      "[ 737    0   26    0    0  224 1606    0 2049  358]\n",
      "cost: 23.36611624554632, train accuracy: 0.24, validation accuracy: 0.2054\n",
      "iterations finished: 41 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[9 9 9 9 9 3 9 3 5 4 0 7 3 3 5 7 5 9 7 0 7 7 7 3 5 4 9 4 9 7 9 5 7 7 4 9 7\n",
      " 7 4 7 9 9 9 9 0 5 9 9 5 9 3 7 7 7 0 9 7 7 7 7 5 5 7 7 9 0 9 7 9 0 9 7 5 2\n",
      " 5 7 7 7 3 9 9 2 0 7 4 9 9 5 9 3 7 0 0 9 9 9 4 4 0 0]\n",
      "[11  0  2  8  8 12  0 28  0 31]\n",
      "[5 0 0 ..., 7 3 2]\n",
      "[ 434    0  172  377  369  682    0 1242   77 1647]\n",
      "cost: 24.043108906236167, train accuracy: 0.23, validation accuracy: 0.1938\n",
      "iterations finished: 51 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[5 6 3 9 9 6 3 6 6 6 3 5 0 5 6 3 5 9 5 6 5 6 6 9 6 3 3 5 3 6 5 0 3 5 6 3 9\n",
      " 9 7 9 3 3 5 9 3 6 9 5 5 3 9 6 3 9 3 3 6 6 6 3 5 6 3 6 6 9 6 3 3 3 6 9 5 6\n",
      " 5 9 3 5 5 3 9 9 5 3 7 6 9 5 3 6 9 3 9 6 9 3 6 0 3 5]\n",
      "[ 3  0  0 28  0 20 27  2  0 20]\n",
      "[5 3 3 ..., 3 3 5]\n",
      "[  85    7    0 1240    0 1269 1375  106    6  912]\n",
      "cost: 25.462662361043193, train accuracy: 0.22, validation accuracy: 0.175\n",
      "iterations finished: 61 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[4 8 5 8 9 8 8 5 8 2 8 8 8 8 8 2 1 8 8 8 8 5 8 8 4 8 8 5 8 5 8 2 5 8 8 8 8\n",
      " 8 8 8 5 5 5 8 8 5 8 8 5 2 2 8 4 8 8 8 8 2 5 2 8 8 8 8 4 2 5 8 5 8 8 8 8 1\n",
      " 8 5 8 5 5 8 5 8 8 8 2 8 8 8 8 8 8 2 8 8 5 5 8 8 8 4]\n",
      "[ 0  2 10  0  5 20  0  0 62  1]\n",
      "[5 8 8 ..., 8 2 8]\n",
      "[  49   55  548    0  310  858   12   22 3020  126]\n",
      "cost: 23.999055562610994, train accuracy: 0.23, validation accuracy: 0.1774\n",
      "iterations finished: 71 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[8 2 8 2 6 6 9 6 2 6 2 8 6 9 9 8 6 8 9 0 8 9 8 5 8 8 8 8 8 6 2 8 8 6 6 8 8\n",
      " 9 9 6 8 8 8 1 8 2 5 8 8 8 9 1 9 9 6 8 6 8 9 1 6 6 9 8 2 9 6 2 6 2 6 9 0 8\n",
      " 2 2 8 5 6 8 2 8 8 0 8 9 6 8 6 8 6 9 6 2 8 2 8 8 6 2]\n",
      "[ 3  3 15  0  0  3 23  0 37 16]\n",
      "[5 8 8 ..., 8 2 8]\n",
      "[ 124   82  728    0    0  325 1068   24 2105  544]\n",
      "cost: 25.21987114955664, train accuracy: 0.31, validation accuracy: 0.2332\n",
      "iterations finished: 81 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "[8 0 7 8 0 5 2 8 0 8 0 8 2 5 5 4 0 8 8 5 8 5 5 5 0 0 0 8 7 2 8 0 4 0 8 5 4\n",
      " 2 5 2 2 2 0 2 8 0 0 7 0 5 8 0 7 0 8 8 2 2 8 0 8 0 2 0 5 7 9 8 8 7 0 0 0 7\n",
      " 0 8 4 4 2 8 2 2 5 8 8 7 5 5 0 7 0 2 0 8 0 5 8 0 0 4]\n",
      "[29  0 15  0  6 15  0  9 25  1]\n",
      "[5 8 0 ..., 5 5 5]\n",
      "[1090   10  387    0  422 1437   52  242 1276   84]\n",
      "cost: 25.599651712184826, train accuracy: 0.22, validation accuracy: 0.214\n",
      "iterations finished: 91 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "Activations 0 Mean 0.467880259395 SD 0.246187959766 Min 0.0 Max 1.0\n",
      "Activations 1 Mean 0.240031513422 SD 0.473913103577 Min 0.0 Max 4.48190850329\n",
      "Activations 2 Mean -0.118660550835 SD 0.654803568528 Min -2.6518703991 Max 1.9847413823\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEICAYAAABMGMOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204dddad4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 9 9 5 9 8 6 6 3 6 6 9 3 6 9 6 8 7 9 3 3 9 5 6 6 0 9 6 0 6 6 2 9 6 6 8 9\n",
      " 9 9 6 3 9 3 6 9 6 6 6 1 9 9 3 6 6 9 6 3 9 6 1 6 8 6 9 8 9 6 9 1 6 6 9 9 9\n",
      " 6 3 8 5 8 8 9 6 6 9 9 9 6 6 9 8 6 6 6 1 1 9 6 8 9 6]\n",
      "[ 2  5  1  9  0  3 38  1 10 31]\n",
      "[6 1 1 ..., 1 3 6]\n",
      "[  36  380   22  197    0  196 1566  168  528 1907]\n",
      "cost: 24.898883958065145, train accuracy: 0.25, validation accuracy: 0.2184\n",
      "iterations finished: 101 alpha: 0.001 reg. lambda: 0.0\n",
      "\n",
      "\n",
      "Weights 0 Mean 9.18879611685e-05 SD 0.0102587677141\n",
      "Weights 1 Mean -0.000111100975501 SD 0.0303783070056\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123456)\n",
    "#layer_dimensions = [X_train.shape[0], 100, 100, 50, 10]  # including the input and output layers\n",
    "layer_dimensions = [X_train.shape[0], 100, 10]  # including the input and output layers\n",
    "NN = NeuralNetwork(layer_dimensions, K_iters_alpha_drop=500, gamma=.90, do_reflection=False)\n",
    "NN.train(X_train, y_train, iters=50000, alpha=0.001, batch_size=100, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = NN.predict(X_test)\n",
    "save_predictions('ans1-uni', y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test if your numpy file has been saved correctly\n",
    "loaded_y = np.load('ans1-uni.npy')\n",
    "print(loaded_y.shape)\n",
    "loaded_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2: Regularizing the neural network\n",
    "#### Add dropout and L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(777777)\n",
    "layer_dimensions = [X_train.shape[0], 100, 10]  # including the input and output layers\n",
    "NN2 = NeuralNetwork(layer_dimensions, drop_prob=.25, reg_lambda=.01, K_iters_alpha_drop=500, gamma=.90, do_reflection=False)\n",
    "NN2.train(X_train, y_train, iters=50000, alpha=0.001, batch_size=100, print_every=10)#alpha=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted2 = NN2.predict(X_test)\n",
    "save_predictions('ans2-uni',y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
